# Raspberry Pi 5 (8GB) low-latency profile
# Loaded by default via scripts/start.sh

HOST=0.0.0.0
PORT=8000
OLLAMA_PORT=11434

# Model used at runtime
OLLAMA_MODEL=gemma:2b

# Keep model resident to avoid cold-start latency
OLLAMA_KEEP_ALIVE=30m
OLLAMA_WARMUP=true

# Benchmarked fast settings on Pi 5
N_CTX=512
N_THREADS=4
MAX_TOKENS=96

# Queue/runtime defaults
MAX_CONCURRENT_REQUESTS=4
MAX_QUEUE_SIZE=100
API_KEYS_DB=api_keys.db

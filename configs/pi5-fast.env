# Raspberry Pi 5 (8GB) low-latency profile
# Loaded by default via scripts/start.sh

HOST=0.0.0.0
PORT=8000
OLLAMA_PORT=11434

# Model used at runtime (smarter multilingual default)
OLLAMA_MODEL=qwen2.5:3b

# Keep model resident to avoid cold-start latency
OLLAMA_KEEP_ALIVE=30m
OLLAMA_WARMUP=true

# Benchmarked fast settings on Pi 5
N_CTX=512
N_THREADS=4
MAX_TOKENS=96
MAX_REQUEST_TOKENS_CAP=128
BUSY_MAX_TOKENS=64
MAX_QUEUE_WAIT_S=20
SYNC_RESPONSE_TIMEOUT_S=45

# Queue/runtime defaults
MAX_CONCURRENT_REQUESTS=1
MAX_QUEUE_SIZE=8
API_KEYS_DB=api_keys.db
